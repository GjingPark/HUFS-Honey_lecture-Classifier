import streamlit as st
import torch
import gdown
import os
import re
import time
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ë§ì¶¤í˜• íŒ€í”Œ ë° ê³¼ì œ ë¶€ë‹´ ìµœì†Œí™” ê°•ì˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ", page_icon="ğŸ“")

# ==========================================
# 1. ì„¤ì • ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
# ==========================================
TEAMPLAY_FILE_ID = '1hcl250N4eFpdCpxIZlJNLQAv5FJpUvRX'  # model.pt ID
BURDEN_FILE_ID   = '1fCQ8Qr_GxJtcqAn7l91_Bf64GdDfRyyC'  # burden_model.pt ID 

MODEL_NAME = "monologg/distilkobert"
MAX_LEN = 128
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

@st.cache_resource
def load_models():
    # 1. íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    if not os.path.exists('model.pt'):
        gdown.download(f'https://drive.google.com/uc?id={TEAMPLAY_FILE_ID}', 'model.pt', quiet=True)
    if not os.path.exists('burden_model.pt'):
        gdown.download(f'https://drive.google.com/uc?id={BURDEN_FILE_ID}', 'burden_model.pt', quiet=True)

    # 2. í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)
    
    # 3. íŒ€í”Œ ëª¨ë¸ ë¡œë“œ
    model_cls = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2, trust_remote_code=True)
    try:
        model_cls.load_state_dict(torch.load('model.pt', map_location=device, weights_only=False))
    except:
        model_cls.load_state_dict(torch.load('model.pt', map_location=device))
    model_cls.to(device).eval()

    # 4. ê³¼ì œ ë¶€ë‹´ ëª¨ë¸ ë¡œë“œ
    model_reg = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1, trust_remote_code=True)
    try:
        model_reg.load_state_dict(torch.load('burden_model.pt', map_location=device, weights_only=False))
    except:
        model_reg.load_state_dict(torch.load('burden_model.pt', map_location=device))
    model_reg.to(device).eval()

    return tokenizer, model_cls, model_reg

# ==========================================
# 2. ìŠ¤ë§ˆíŠ¸ íŒŒì‹± í•¨ìˆ˜
# ==========================================
def parse_raw_text(raw_text):
    text = raw_text.replace("\n", " ")

    # (1) ê³¼ëª©ëª…
    title_match = re.search(r"\(Course Title\)(.*?)ì´ìˆ˜êµ¬ë¶„", text)
    title = title_match.group(1).strip() if title_match else "ê³¼ëª©ëª… ë¯¸í™•ì¸"

    # (2) ìˆ˜ì—…ê°œìš”
    desc_match = re.search(r"\(Course Description.*?Objectives\)(.*?)êµì¬", text)
    if not desc_match: 
        desc_match = re.search(r"\(Course Description.*?Objectives\)(.*?)ì°¸ê³ ë¬¸í—Œ", text)
    desc = desc_match.group(1).strip() if desc_match else ""

    # (3) ìˆ˜ì—…ë°©ì‹
    method_match = re.search(r"\(Teaching Methods\)(.*?)í•™ìŠµí‰ê°€ë°©ë²•", text)
    method = method_match.group(1).strip() if method_match else ""

    # (4) ê¸°íƒ€ì•ˆë‚´
    note_match = re.search(r"\(Other Information.*?Notices\)(.*?)ì£¼ì°¨\(Week\)", text)
    note = note_match.group(1).strip() if note_match else ""

    if not title and not desc:
        return raw_text, "ì§ì ‘ ì…ë ¥ ëª¨ë“œ"

    full_text = f"ê³¼ëª©ëª…: {title} / ìˆ˜ì—…ê°œìš”: {desc} / ìˆ˜ì—…ë°©ì‹: {method} / ê¸°íƒ€ì‚¬í•­: {note}"
    
    return full_text, title

# ==========================================
# 3. ì¶”ë¡  ë¡œì§
# ==========================================
def analyze(text, tokenizer, model_cls, model_reg):
    inputs = tokenizer(text, return_tensors='pt', max_length=MAX_LEN, truncation=True, padding='max_length')
    input_ids = inputs['input_ids'].to(device)
    attention_mask = inputs['attention_mask'].to(device)

    with torch.no_grad():
        out_cls = model_cls(input_ids=input_ids, attention_mask=attention_mask)
        probs = F.softmax(out_cls.logits, dim=1)
        prob_team = probs[0][1].item() * 100
        is_team = torch.argmax(out_cls.logits, dim=1).item()

        out_reg = model_reg(input_ids=input_ids, attention_mask=attention_mask)
        burden_score = out_reg.logits.item() * 100
        
        if is_team == 1:
            burden_score = burden_score * 1.5 + 20
        burden_score = min(max(burden_score, 0), 100)

    return is_team, prob_team, burden_score

# ==========================================
# 4. Streamlit UI êµ¬ì„±
# ==========================================

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'analyzed' not in st.session_state:
    st.session_state['analyzed'] = False
if 'result' not in st.session_state:
    st.session_state['result'] = {}
if 'feedback_submitted' not in st.session_state:
    st.session_state['feedback_submitted'] = False
# ì…ë ¥ì°½ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ Key ê´€ë¦¬
if 'input_key' not in st.session_state:
    st.session_state['input_key'] = 0

st.title("íŒ€í”Œ ë° ê³¼ì œ ë¶€ë‹´ ìµœì†Œí™” ê°•ì˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ")
st.markdown("""
**ê°•ì˜ê³„íšì„œ ì „ì²´ë¥¼ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”!**
\n AIê°€ ë¶„ì„ì— í•„ìš”í•œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ë¶„ì„í•˜ê² ìŠµë‹ˆë‹¤. 
""")

with st.sidebar:
    st.header("About Project")
    st.write("### AIê°€ ê°•ì˜ê³„íšì„œë¥¼ í†µí•´ íŒ€í”Œ ìœ ë¬´ì™€, ê³¼ì œ ë¶€ë‹´ ì§€ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
    st.write("### Student ID/Name: 202401394 ë°•ì˜ì§„")
    st.write("### Model: Dual DistilKoBERT")
    st.write("### Credit : Gemini pro 3ì˜ ë„ì›€ì„ ë°›ì•„ ì œì‘í•˜ì˜€ìŠµë‹ˆë‹¤.")

# key ê°’ì„ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì—¬, ë¦¬ì…‹ ë²„íŠ¼ í´ë¦­ ì‹œ ê°•ì œë¡œ ìƒˆ ì…ë ¥ì°½ì„ ìƒì„±í•˜ê²Œ í•¨
raw_input = st.text_area(
    "ê°•ì˜ê³„íšì„œ ì „ì²´ í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°:", 
    height=300, 
    placeholder="ì¢…í•©ì •ë³´ì‹œìŠ¤í…œ ê°•ì˜ê³„íšì„œ í™”ë©´ì„ ì „ì²´ ë³µì‚¬(Ctrl+A, Ctrl+C)í•´ì„œ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.",
    key=f"syllabus_input_{st.session_state['input_key']}" 
)

if st.button("ê°•ì˜ ë¶„ë¥˜ ì‹œì‘", type="primary"):
    if not raw_input:
        st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    else:
        # ì§„í–‰ë°”
        progress_text = "AI ë¶„ì„ ì¤€ë¹„ ì¤‘..."
        my_bar = st.progress(0, text=progress_text)

        time.sleep(0.3)
        my_bar.progress(30, text="ğŸ“¥ ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë”© ì¤‘...")
        tokenizer, model_cls, model_reg = load_models()
        
        time.sleep(0.3)
        my_bar.progress(60, text="ğŸ” í…ìŠ¤íŠ¸ í•µì‹¬ ì •ë³´ ì¶”ì¶œ ì¤‘...")
        final_input, course_title = parse_raw_text(raw_input)
        
        time.sleep(0.3)
        my_bar.progress(90, text="ğŸ¤– íŒ€í”Œ ìœ„í—˜ë„ ë° ê³¼ì œ ë¶€ë‹´ ì˜ˆì¸¡ ì¤‘...")
        is_team, prob_team, burden = analyze(final_input, tokenizer, model_cls, model_reg)
        
        my_bar.progress(100, text="âœ… ë¶„ì„ ì™„ë£Œ!")
        time.sleep(0.3)
        my_bar.empty()

        # ê²°ê³¼ ì €ì¥ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
        st.session_state['analyzed'] = True
        st.session_state['feedback_submitted'] = False
        st.session_state['result'] = {
            'course_title': course_title,
            'is_team': is_team,
            'prob_team': prob_team,
            'burden': burden,
            'final_input': final_input
        }
        st.rerun()

# ê²°ê³¼ í™”ë©´ í‘œì‹œ
if st.session_state['analyzed']:
    res = st.session_state['result']
    
    st.divider()
    st.subheader(f"ğŸ“‚ ë¶„ì„ ê²°ê³¼: {res['course_title']}")
    
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("íŒ€í”Œ ìœ„í—˜ë„")
        if res['is_team'] == 1:
            st.error(f"ğŸš¨ íŒ€í”Œ ìˆìŒ ({res['prob_team']:.1f}%)")
            st.write("ì¡°ë³„ ê³¼ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. \nìˆ˜ê°• ì‹œ ìœ ì˜í•˜ì„¸ìš”!")
        else:
            st.success(f"ğŸ€ íŒ€í”Œ ì—†ìŒ ({res['prob_team']:.1f}%)")
            st.write("ê°œì¸ ê³¼ì œ ìœ„ì£¼ì´ê±°ë‚˜ \nì´ë¡  ìˆ˜ì—…ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.")

    with col2:
        st.subheader("ê³¼ì œ ë¶€ë‹´ ì§€ìˆ˜")
        st.metric(label="Burden Score", value=f"{res['burden']:.1f}/100ì ")
        if res['burden'] > 60:
            st.write("ğŸ”¥ **ìˆ˜ê°• ì£¼ì˜** ğŸ”¥ (ê³¼ì œ ë§ìŒ)")
        elif res['burden'] > 30:
            st.write("**ë³´í†µ**")
        else:
            st.write("ğŸ¯ **ê¿€ê°• í™•ì •** ğŸ¯ (ê³¼ì œ ì ìŒ)")
    
    st.divider()
    
    # [ìˆ˜ì •ë¨] í•˜ì´ë¼ì´íŒ… ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ í‘œì‹œ
    with st.expander("ğŸ¤– AIê°€ ì¶”ì¶œí•œ í•µì‹¬ ë‚´ìš© ë³´ê¸° (íŒë‹¨ ê·¼ê±°)"):
        st.code(res['final_input'], language="text")
        st.caption("AIëŠ” ìœ„ ê³„íšì„œì—ì„œ ê°œìš”, í‰ê°€ë°©ì‹, ê¸°íƒ€ ë“±ì˜ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤.")

    st.divider()
    st.markdown("##### ğŸ“¢ ë¶„ì„ ê²°ê³¼ê°€ ì •í™•í•œê°€ìš”?")
    
    # í”¼ë“œë°± ì˜ì—­
    if not st.session_state['feedback_submitted']:
        col_f1, col_f2, col_f3 = st.columns([1, 1, 3])
        
        if col_f1.button("ğŸ‘ ì •í™•í•´ìš”"):
            st.session_state['feedback_submitted'] = True
            st.rerun() 

        if col_f2.button("ğŸ‘ í‹€ë ¸ì–´ìš”"):
            st.session_state['feedback_submitted'] = True
            st.rerun() 
            
    else:
        st.success("âœ… í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤! ëª¨ë¸ ê°œì„ ì— í™œìš©í•˜ê² ìŠµë‹ˆë‹¤. ğŸ™‡â€â™‚ï¸")

    # ë¦¬ì…‹ ë²„íŠ¼
    st.divider()
    if st.button("ğŸ”„ ë‹¤ë¥¸ ê°•ì˜ ë¶„ì„í•˜ê¸°"):
        st.session_state['analyzed'] = False
        st.session_state['result'] = {}
        st.session_state['feedback_submitted'] = False
        st.session_state['input_key'] += 1 
        st.rerun()